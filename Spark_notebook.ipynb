{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a data about user behavior before subscription and after 3 weeks. We need to detect users who churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have following features:  \n",
    "* type of subscription\n",
    "* locale of interface\n",
    "* have news subscription\n",
    "* number of books added to library\n",
    "* number of finished books\n",
    "* use or not promocode\n",
    "* number of following shelves\n",
    "* number of friends\n",
    "* number of quotes\n",
    "* number of likes\n",
    "* length of sessions\n",
    "* from what chanel subscriptions was buying\n",
    "* e.t.c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 100\n",
      "Number of samples = 21516\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('churned_data.csv', index_col='user_id')\n",
    "columns = df.columns\n",
    "print('Number of features = {}'.format(len(columns)))\n",
    "print('Number of samples = {}'.format(df.shape[0]))\n",
    "# for i in columns:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>locale</th>\n",
       "      <th>subscription_news</th>\n",
       "      <th>added_to_lib_0_week</th>\n",
       "      <th>added_to_lib_1_week</th>\n",
       "      <th>added_to_lib_2_week</th>\n",
       "      <th>added_to_lib_3_week</th>\n",
       "      <th>finished_books_0_week</th>\n",
       "      <th>finished_books_1_week</th>\n",
       "      <th>finished_books_2_week</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_pop_dyn_21</th>\n",
       "      <th>avg_pop_dyn_31</th>\n",
       "      <th>avg_pop_dyn_32</th>\n",
       "      <th>count_session_per_day_1</th>\n",
       "      <th>count_session_per_day_2</th>\n",
       "      <th>count_session_per_day_3</th>\n",
       "      <th>AndroidInApp</th>\n",
       "      <th>Braintree</th>\n",
       "      <th>InApp</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "      <td>21516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.261154</td>\n",
       "      <td>0.962307</td>\n",
       "      <td>0.969929</td>\n",
       "      <td>8.887200</td>\n",
       "      <td>5.854155</td>\n",
       "      <td>1.735546</td>\n",
       "      <td>1.375813</td>\n",
       "      <td>0.660578</td>\n",
       "      <td>0.649191</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>...</td>\n",
       "      <td>116.034436</td>\n",
       "      <td>108.471430</td>\n",
       "      <td>286.880200</td>\n",
       "      <td>2.253295</td>\n",
       "      <td>1.408744</td>\n",
       "      <td>1.133262</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.126975</td>\n",
       "      <td>0.769753</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.439274</td>\n",
       "      <td>0.190457</td>\n",
       "      <td>0.170786</td>\n",
       "      <td>32.212863</td>\n",
       "      <td>19.669411</td>\n",
       "      <td>8.193867</td>\n",
       "      <td>10.443027</td>\n",
       "      <td>5.896316</td>\n",
       "      <td>1.686822</td>\n",
       "      <td>1.413622</td>\n",
       "      <td>...</td>\n",
       "      <td>2101.691247</td>\n",
       "      <td>2084.790122</td>\n",
       "      <td>3769.629078</td>\n",
       "      <td>1.259408</td>\n",
       "      <td>1.479215</td>\n",
       "      <td>1.381644</td>\n",
       "      <td>0.304321</td>\n",
       "      <td>0.332953</td>\n",
       "      <td>0.421001</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998555</td>\n",
       "      <td>-0.998810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.916085</td>\n",
       "      <td>-0.968868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>870.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>203030.000000</td>\n",
       "      <td>176179.000000</td>\n",
       "      <td>357155.000000</td>\n",
       "      <td>9.857143</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               kind        locale  subscription_news  added_to_lib_0_week  \\\n",
       "count  21516.000000  21516.000000       21516.000000         21516.000000   \n",
       "mean       0.261154      0.962307           0.969929             8.887200   \n",
       "std        0.439274      0.190457           0.170786            32.212863   \n",
       "min        0.000000      0.000000           0.000000             0.000000   \n",
       "25%        0.000000      1.000000           1.000000             3.000000   \n",
       "50%        0.000000      1.000000           1.000000             4.000000   \n",
       "75%        1.000000      1.000000           1.000000             6.000000   \n",
       "max        1.000000      1.000000           1.000000          1480.000000   \n",
       "\n",
       "       added_to_lib_1_week  added_to_lib_2_week  added_to_lib_3_week  \\\n",
       "count         21516.000000         21516.000000         21516.000000   \n",
       "mean              5.854155             1.735546             1.375813   \n",
       "std              19.669411             8.193867            10.443027   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               1.000000             0.000000             0.000000   \n",
       "75%               5.000000             1.000000             0.000000   \n",
       "max             870.000000           425.000000          1091.000000   \n",
       "\n",
       "       finished_books_0_week  finished_books_1_week  finished_books_2_week  \\\n",
       "count           21516.000000           21516.000000           21516.000000   \n",
       "mean                0.660578               0.649191               0.291318   \n",
       "std                 5.896316               1.686822               1.413622   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 0.000000               0.000000               0.000000   \n",
       "75%                 0.000000               1.000000               0.000000   \n",
       "max               326.000000              51.000000             153.000000   \n",
       "\n",
       "           ...       avg_pop_dyn_21  avg_pop_dyn_31  avg_pop_dyn_32  \\\n",
       "count      ...         21516.000000    21516.000000    21516.000000   \n",
       "mean       ...           116.034436      108.471430      286.880200   \n",
       "std        ...          2101.691247     2084.790122     3769.629078   \n",
       "min        ...            -0.999998       -0.999998       -0.999998   \n",
       "25%        ...            -0.998555       -0.998810        0.000000   \n",
       "50%        ...            -0.916085       -0.968868        0.000000   \n",
       "75%        ...             0.000000        0.000000        0.000000   \n",
       "max        ...        203030.000000   176179.000000   357155.000000   \n",
       "\n",
       "       count_session_per_day_1  count_session_per_day_2  \\\n",
       "count             21516.000000             21516.000000   \n",
       "mean                  2.253295                 1.408744   \n",
       "std                   1.259408                 1.479215   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   1.333333                 0.000000   \n",
       "50%                   2.000000                 1.000000   \n",
       "75%                   3.000000                 2.166667   \n",
       "max                   9.857143                23.500000   \n",
       "\n",
       "       count_session_per_day_3  AndroidInApp     Braintree         InApp  \\\n",
       "count             21516.000000  21516.000000  21516.000000  21516.000000   \n",
       "mean                  1.133262      0.103272      0.126975      0.769753   \n",
       "std                   1.381644      0.304321      0.332953      0.421001   \n",
       "min                   0.000000      0.000000      0.000000      0.000000   \n",
       "25%                   0.000000      0.000000      0.000000      1.000000   \n",
       "50%                   1.000000      0.000000      0.000000      1.000000   \n",
       "75%                   2.000000      0.000000      0.000000      1.000000   \n",
       "max                  11.166667      1.000000      1.000000      1.000000   \n",
       "\n",
       "            churned  \n",
       "count  21516.000000  \n",
       "mean       0.500000  \n",
       "std        0.500012  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.500000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg_session - median_session\n",
    "df = pd.read_csv('churned_data.csv', index_col='user_id')\n",
    "df['sessions_skewness_1'] = df['avg_sessions_1'] - df['median_sessions_1']\n",
    "df['sessions_skewness_2'] = df['avg_sessions_2'] - df['median_sessions_2']\n",
    "df['sessions_skewness_3'] = df['avg_sessions_3'] - df['median_sessions_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PySpark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_point(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[0], values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_data = sc.textFile(\"churned_data_spark.csv\").map(parse_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TP_TN_FP_FN(prediction_and_labels):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = prediction_and_labels.filter(lambda (x, y): x == 1 and x == y).count()\n",
    "    TN = prediction_and_labels.filter(lambda (x, y): x == 0 and x == y).count()\n",
    "    FP = prediction_and_labels.filter(lambda (x, y): x == 1 and x != y).count()\n",
    "    FN = prediction_and_labels.filter(lambda (x, y): x == 0 and x != y).count()\n",
    "    \n",
    "    return [TP, TN, FP, FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(arr):\n",
    "    print('{} --- {}'.format(arr[0], arr[2]))\n",
    "    print('{} --- {}'.format(arr[3], arr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create 5 folds cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for _ in xrange(5):\n",
    "    tr_rdd, test_rdd = parsed_data.randomSplit([0.75, 0.25])\n",
    "    SVM_model = SVMWithSGD.train(tr_rdd, iterations=100, step=1, regParam=0.01, miniBatchFraction=0.5)\n",
    "    prediction_label = test_rdd.map(lambda p: (float(SVM_model.predict(p.features)), p.label))\n",
    "    stat_arr = TP_TN_FP_FN(prediction_label)\n",
    "    accuracy.append((stat_arr[0] + stat_arr[1]) / float(sum(stat_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4928050831620258, 0.502851885924563, 0.49953139643861294, 0.5447636700648749, 0.4987724268177526]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507744892482\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 --- 5\n",
      "2649 --- 2627\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(stat_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for _ in xrange(5):\n",
    "    tr_rdd, test_rdd = parsed_data.randomSplit([0.75, 0.25])\n",
    "    LR_model = LogisticRegressionWithLBFGS.train(tr_rdd)\n",
    "    prediction_label = test_rdd.map(lambda p: (float(LR_model.predict(p.features)), p.label))\n",
    "    stat_arr = TP_TN_FP_FN(prediction_label)\n",
    "    accuracy.append((stat_arr[0] + stat_arr[1]) / float(sum(stat_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6052290005562767, 0.5983712752174718, 0.609220241311003, 0.6026022304832713, 0.6130930489150423]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605703159297\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860 --- 1236\n",
      "868 --- 1474\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(stat_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('churned_data.csv', index_col='user_id')\n",
    "X_data = df.drop('churned', axis=1).values\n",
    "y_data = df['churned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth=12,\n",
    "                              learning_rate=0.001,\n",
    "                              n_estimators=50,\n",
    "                              subsample=0.6,\n",
    "                              colsample_bytree=1.0,\n",
    "                              nthread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in xrange(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_test_pred = xgb_model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_test_pred))\n",
    "    precision.append(precision_score(y_test, y_test_pred))\n",
    "    recall.append(recall_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77579475738984938, 0.77876928797174194, 0.78750697155605132, 0.78304517568321252, 0.77858337981037362]\n",
      "[0.73196537351715296, 0.73774586325320013, 0.73944954128440366, 0.73099596649084708, 0.73800623052959502]\n",
      "[0.86053524312099505, 0.87099152230003685, 0.89258028792912514, 0.88704819277108438, 0.87127620448694376]\n",
      "Mean accuracy on 5-folds cross validation = 0.780739914482\n",
      "Mean precision on 5-folds cross validation = 0.735632595015\n",
      "Mean recall on 5-folds cross validation = 0.876486290122\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print('Mean accuracy on 5-folds cross validation = {}'.format(np.mean(accuracy)))\n",
    "print('Mean precision on 5-folds cross validation = {}'.format(np.mean(precision)))\n",
    "print('Mean recall on 5-folds cross validation = {}'.format(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1819  841]\n",
      " [ 350 2369]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Theanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theanets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('churned_data.csv', index_col='user_id')\n",
    "X_data = df.drop('churned', axis=1).values\n",
    "y_data = df['churned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25)\n",
    "print(X_train.shape[1])\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "y_validation = y_validation.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[2155 2146]\n",
      " [   3    0]]\n",
      "Accuracy score = 0.500697026022\n"
     ]
    }
   ],
   "source": [
    "hidden = 50\n",
    "simple_net = theanets.Classifier(layers=[99, hidden, 30, (2, 'softmax')])\n",
    "simple_net.train(\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    algo='nag',\n",
    "    learning_rate=1e-1,\n",
    "    momentum=0.8\n",
    ")\n",
    "\n",
    "y_predicted = simple_net.predict(X_test)\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y_predicted, y_test))\n",
    "print('Accuracy score = {}'.format(accuracy_score(y_predicted, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.2)",
   "language": "python",
   "name": "python_spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
